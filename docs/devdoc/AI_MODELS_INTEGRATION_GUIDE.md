# AIå¤šæ¨¡å‹é›†æˆç³»ç»Ÿä½¿ç”¨æŒ‡å—

> **ç‰ˆæœ¬**: v1.0  
> **åˆ›å»ºæ—¶é—´**: 2025-01  
> **é¡¹ç›®**: éŸ³ä¹åˆ›ä½œå¹³å°AIå¤šæ¨¡å‹ç³»ç»Ÿ

---

## ğŸ“‹ ç›®å½•

- [1. ç³»ç»Ÿæ¦‚è¿°](#1-ç³»ç»Ÿæ¦‚è¿°)
- [2. å¿«é€Ÿå¼€å§‹](#2-å¿«é€Ÿå¼€å§‹)
- [3. æ¶æ„è®¾è®¡](#3-æ¶æ„è®¾è®¡)
- [4. APIæ¥å£æ–‡æ¡£](#4-apiæ¥å£æ–‡æ¡£)
- [5. ç®¡ç†åå°ä½¿ç”¨](#5-ç®¡ç†åå°ä½¿ç”¨)
- [6. å¼€å‘é›†æˆ](#6-å¼€å‘é›†æˆ)
- [7. æœ€ä½³å®è·µ](#7-æœ€ä½³å®è·µ)
- [8. æ•…éšœæ’æŸ¥](#8-æ•…éšœæ’æŸ¥)

---

## 1. ç³»ç»Ÿæ¦‚è¿°

### 1.1 åŠŸèƒ½ç‰¹æ€§

æœ¬ç³»ç»Ÿæä¾›äº†å®Œæ•´çš„AIå¤šæ¨¡å‹ç®¡ç†å’Œè°ƒç”¨èƒ½åŠ›ï¼š

âœ… **å¤šProvideræ”¯æŒ**
- OpenAI (GPT-4o, GPT-4 Turbo, GPT-3.5-turbo)
- Anthropic Claude (Claude 3.5 Sonnet, Claude 3.5 Haiku, Claude 3 Opus)
- DeepSeek (DeepSeek Chat, DeepSeek Reasoner, DeepSeek Coder)

âœ… **æ ¸å¿ƒåŠŸèƒ½**
- å¤šAPI Keyè½®è¯¢å’Œè´Ÿè½½å‡è¡¡
- æ™ºèƒ½é”™è¯¯é‡è¯•(æŒ‡æ•°é€€é¿)
- Tokenä½¿ç”¨ç»Ÿè®¡å’Œæˆæœ¬è®¡ç®—
- å®Œæ•´çš„è°ƒç”¨æ—¥å¿—è®°å½•
- é€Ÿç‡é™åˆ¶ç®¡ç†
- è‡ªåŠ¨æ¨¡å‹åˆ—è¡¨åŒæ­¥

âœ… **ç®¡ç†èƒ½åŠ›**
- Provideré…ç½®ç®¡ç†
- API Keyç®¡ç†(æ”¯æŒå¤škey)
- Modelé…ç½®ç®¡ç†
- ä½¿ç”¨ç»Ÿè®¡å’Œè¶‹åŠ¿åˆ†æ
- é”™è¯¯ç›‘æ§å’Œå‘Šè­¦

### 1.2 æŠ€æœ¯æ ˆ

- **åç«¯**: NestJS + TypeScript
- **æ•°æ®åº“**: MySQL 8.0+
- **SDK**: 
  - `openai` (OpenAIå®˜æ–¹SDK)
  - `@anthropic-ai/sdk` (Claudeå®˜æ–¹SDK)
- **ORM**: TypeORM

---

## 2. å¿«é€Ÿå¼€å§‹

### 2.1 å®‰è£…ä¾èµ–

```bash
cd backend
npm install openai @anthropic-ai/sdk mysql2
```

### 2.2 æ•°æ®åº“åˆå§‹åŒ–

```bash
# è¿è¡Œæ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
node scripts/init-ai-models-db.js
```

è¿™å°†åˆ›å»ºä»¥ä¸‹è¡¨ï¼š
- `t_ai_providers` - AIä¾›åº”å•†
- `t_ai_api_keys` - APIå¯†é’¥
- `t_ai_models` - AIæ¨¡å‹
- `t_ai_api_logs` - APIè°ƒç”¨æ—¥å¿—
- `t_ai_usage_stats` - ä½¿ç”¨ç»Ÿè®¡

### 2.3 æ·»åŠ API Key

æœ‰ä¸¤ç§æ–¹å¼æ·»åŠ API Keyï¼š

#### æ–¹å¼1: é€šè¿‡APIæ¥å£

```bash
curl -X POST http://localhost:3000/api/admin/ai-providers/1/keys \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_JWT_TOKEN" \
  -d '{
    "providerId": 1,
    "keyName": "OpenAIä¸»Key",
    "apiKey": "sk-proj-...",
    "priority": 100,
    "rateLimitRpm": 3500,
    "rateLimitTpm": 90000,
    "rateLimitRpd": 200000
  }'
```

#### æ–¹å¼2: ç›´æ¥æ’å…¥æ•°æ®åº“

```sql
INSERT INTO t_ai_api_keys (provider_id, key_name, api_key, priority, rate_limit_rpm, rate_limit_tpm, rate_limit_rpd)
VALUES (1, 'OpenAIä¸»Key', 'sk-proj-...', 100, 3500, 90000, 200000);
```

### 2.4 é›†æˆåˆ°AppModule

```typescript
// src/app.module.ts
import { AIModelsModule } from './modules/ai-models/ai-models.module';

@Module({
  imports: [
    // ... å…¶ä»–æ¨¡å—
    AIModelsModule,
  ],
})
export class AppModule {}
```

### 2.5 ç¬¬ä¸€æ¬¡è°ƒç”¨

```typescript
import { AIClientManagerService } from './modules/ai-models/services/ai-client-manager.service';

@Injectable()
export class YourService {
  constructor(
    private readonly aiClientManager: AIClientManagerService,
  ) {}

  async generateText() {
    const response = await this.aiClientManager.createChatCompletion(
      'openai', // provider code
      {
        messages: [
          { role: 'user', content: 'Hello, how are you?' }
        ],
        model: 'gpt-4o',
        maxTokens: 1000,
        temperature: 0.7,
      },
      userId, // å¯é€‰
      ipAddress, // å¯é€‰
      userAgent, // å¯é€‰
    );

    console.log(response.content);
    console.log(`Tokens used: ${response.usage.totalTokens}`);
  }
}
```

---

## 3. æ¶æ„è®¾è®¡

### 3.1 æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Application Layer                        â”‚
â”‚  (Controllers: AIChat, AIProvider, AIModel, AIStats)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Service Layer                             â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚        AIClientManagerService                        â”‚  â”‚
â”‚  â”‚  (ç»Ÿä¸€è°ƒç”¨å…¥å£ï¼Œé›†æˆæ—¥å¿—ã€ç»Ÿè®¡ã€é”™è¯¯å¤„ç†)            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚             â”‚                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ AIProviderService    â”‚  â”‚ AILogService â”‚  â”‚ AIUsage  â”‚ â”‚
â”‚  â”‚ (Keyé€‰æ‹©ã€è½®è¯¢)      â”‚  â”‚ (æ—¥å¿—è®°å½•)   â”‚  â”‚StatServiceâ”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   AI Client Layer                            â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ OpenAIClient â”‚  â”‚ ClaudeClient â”‚  â”‚DeepSeekClientâ”‚     â”‚
â”‚  â”‚ (openai SDK) â”‚  â”‚(@anthropic)  â”‚  â”‚(OpenAIå…¼å®¹)  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚                   â”‚                   â”‚           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                   â”‚                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              External AI Provider APIs                       â”‚
â”‚  (OpenAI API, Claude API, DeepSeek API)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 å¤šKeyè½®è¯¢ç­–ç•¥

```typescript
// è½®è¯¢ç®—æ³•
function selectAvailableKey(providerId: number): AIApiKey {
  // 1. è·å–æ‰€æœ‰æ´»è·ƒçš„key
  const keys = await getActiveKeys(providerId);
  
  // 2. æŒ‰ä¼˜å…ˆçº§æ’åº (priority DESC)
  keys.sort((a, b) => b.priority - a.priority);
  
  // 3. æ£€æŸ¥é€Ÿç‡é™åˆ¶
  for (const key of keys) {
    if (checkRateLimit(key)) {
      return key; // è¿”å›ç¬¬ä¸€ä¸ªæœªè¾¾åˆ°é™åˆ¶çš„key
    }
  }
  
  // 4. æ‰€æœ‰keyéƒ½è¾¾åˆ°é™åˆ¶ï¼Œè¿”å›æœ€è¿‘æœ€å°‘ä½¿ç”¨çš„
  return keys.sort((a, b) => 
    a.lastUsedAt.getTime() - b.lastUsedAt.getTime()
  )[0];
}
```

### 3.3 é”™è¯¯é‡è¯•æœºåˆ¶

```typescript
// æŒ‡æ•°é€€é¿é‡è¯•
async function executeWithRetry<T>(
  operation: () => Promise<T>,
  maxRetries: number = 3
): Promise<T> {
  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      return await operation();
    } catch (error) {
      // åˆ¤æ–­æ˜¯å¦åº”è¯¥é‡è¯•
      if (!shouldRetry(error) || attempt >= maxRetries) {
        throw error;
      }
      
      // æŒ‡æ•°é€€é¿: 1s, 2s, 4s, 8s
      const backoffMs = Math.min(1000 * Math.pow(2, attempt), 10000);
      await sleep(backoffMs);
    }
  }
}

function shouldRetry(error: any): boolean {
  // ç½‘ç»œé”™è¯¯ - é‡è¯•
  if (error.code === 'ECONNREFUSED' || error.code === 'ETIMEDOUT') {
    return true;
  }
  
  // é€Ÿç‡é™åˆ¶ (429) - é‡è¯•
  if (error.status === 429) {
    return true;
  }
  
  // æœåŠ¡å™¨é”™è¯¯ (500-599) - é‡è¯•
  if (error.status >= 500 && error.status < 600) {
    return true;
  }
  
  // å…¶ä»–é”™è¯¯ - ä¸é‡è¯•
  return false;
}
```

---

## 4. APIæ¥å£æ–‡æ¡£

### 4.1 èŠå¤©å®Œæˆæ¥å£

**POST** `/api/ai/chat/completions`

åˆ›å»ºAIèŠå¤©å®Œæˆè¯·æ±‚ã€‚

#### è¯·æ±‚å‚æ•°

```typescript
{
  "providerCode": "openai",  // å¿…å¡«: openai | anthropic | deepseek
  "messages": [              // å¿…å¡«: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
    {
      "role": "user",        // system | user | assistant
      "content": "Hello!"
    }
  ],
  "model": "gpt-4o",        // å¯é€‰: æ¨¡å‹ä»£ç 
  "maxTokens": 1000,        // å¯é€‰: æœ€å¤§tokenæ•°
  "temperature": 0.7,       // å¯é€‰: 0-2
  "topP": 1.0               // å¯é€‰: 0-1
}
```

#### å“åº”ç¤ºä¾‹

```json
{
  "code": 200,
  "data": {
    "id": "chatcmpl-abc123",
    "content": "Hello! How can I help you today?",
    "model": "gpt-4o",
    "usage": {
      "promptTokens": 10,
      "completionTokens": 15,
      "totalTokens": 25
    },
    "finishReason": "stop",
    "createdAt": "2025-01-15T10:30:00.000Z"
  }
}
```

### 4.2 Providerç®¡ç†æ¥å£

#### è·å–Provideråˆ—è¡¨

**GET** `/api/admin/ai-providers`

```json
{
  "code": 200,
  "data": [
    {
      "id": 1,
      "providerCode": "openai",
      "providerName": "OpenAI",
      "baseUrl": "https://api.openai.com/v1",
      "isActive": true,
      "modelsCount": 4,
      "activeKeysCount": 2
    }
  ]
}
```

#### åˆ›å»ºProvider

**POST** `/api/admin/ai-providers`

```json
{
  "providerCode": "custom-provider",
  "providerName": "Custom AI Provider",
  "baseUrl": "https://api.custom.com",
  "isActive": true,
  "sortOrder": 70,
  "description": "è‡ªå®šä¹‰AIä¾›åº”å•†"
}
```

### 4.3 API Keyç®¡ç†æ¥å£

#### è·å–Keyåˆ—è¡¨

**GET** `/api/admin/ai-providers/:providerId/keys`

```json
{
  "code": 200,
  "data": [
    {
      "id": 1,
      "providerId": 1,
      "keyName": "OpenAIä¸»Key",
      "apiKey": "sk-p...1234",  // å·²è„±æ•
      "priority": 100,
      "isActive": true,
      "status": "normal",
      "requestsCountToday": 1523,
      "tokensCountToday": 45231,
      "lastUsedAt": "2025-01-15T10:25:00.000Z"
    }
  ]
}
```

#### æ·»åŠ API Key

**POST** `/api/admin/ai-providers/:providerId/keys`

```json
{
  "keyName": "OpenAIå¤‡ç”¨Key",
  "apiKey": "sk-proj-...",
  "priority": 90,
  "rateLimitRpm": 3500,
  "rateLimitTpm": 90000,
  "rateLimitRpd": 200000
}
```

#### éªŒè¯API Key

**POST** `/api/admin/ai-providers/keys/:id/validate`

```json
{
  "code": 200,
  "data": {
    "isValid": true
  },
  "message": "API Key is valid"
}
```

### 4.4 Modelç®¡ç†æ¥å£

#### è·å–æ¨¡å‹åˆ—è¡¨

**GET** `/api/admin/ai-models?providerId=1&isActive=true`

```json
{
  "code": 200,
  "data": [
    {
      "id": 1,
      "providerId": 1,
      "modelCode": "gpt-4o",
      "modelName": "GPT-4o",
      "modelType": "chat",
      "maxInputTokens": 128000,
      "maxOutputTokens": 16384,
      "supportsStreaming": true,
      "supportsFunctionCall": true,
      "costPer1kPromptTokens": 0.005,
      "costPer1kCompletionTokens": 0.015,
      "isActive": true,
      "isDefault": true
    }
  ]
}
```

#### åŒæ­¥æ¨¡å‹åˆ—è¡¨

**POST** `/api/admin/ai-providers/:id/sync-models`

ä»Providerçš„APIè‡ªåŠ¨è·å–æœ€æ–°çš„æ¨¡å‹åˆ—è¡¨å¹¶æ›´æ–°æ•°æ®åº“ã€‚

```json
{
  "code": 200,
  "message": "Synced 10 models",
  "data": {
    "count": 10
  }
}
```

### 4.5 ç»Ÿè®¡æ¥å£

#### è·å–ä½¿ç”¨ç»Ÿè®¡

**GET** `/api/admin/ai-stats/usage?startDate=2025-01-01&endDate=2025-01-15&groupBy=day`

```json
{
  "code": 200,
  "data": [
    {
      "date": "2025-01-15",
      "totalRequests": 5230,
      "successCount": 5180,
      "errorCount": 50,
      "totalTokens": 152300,
      "totalCost": 1.523
    }
  ]
}
```

#### è·å–è¶‹åŠ¿æ•°æ®

**GET** `/api/admin/ai-stats/usage/trend?days=30`

```json
{
  "code": 200,
  "data": [
    {
      "date": "2025-01-15",
      "requests": 5230,
      "tokens": 152300,
      "cost": 1.523,
      "successRate": 0.99
    }
  ]
}
```

#### è·å–ä»ªè¡¨ç›˜ç»Ÿè®¡

**GET** `/api/admin/ai-stats/dashboard?days=7`

```json
{
  "code": 200,
  "data": {
    "summary": {
      "totalRequests": 35420,
      "successCount": 35102,
      "errorCount": 318,
      "successRate": 0.991,
      "totalTokens": 1052300,
      "totalCost": 10.523,
      "avgLatencyMs": 1523
    },
    "trend": [...],
    "errors": {
      "totalErrors": 318,
      "errorsByCode": [...],
      "errorsByKey": [...]
    }
  }
}
```

---

## 5. ç®¡ç†åå°ä½¿ç”¨

### 5.1 Providerç®¡ç†

1. **æ·»åŠ Provider**
   - è¿›å…¥"AI Providerç®¡ç†"é¡µé¢
   - ç‚¹å‡»"æ·»åŠ Provider"
   - å¡«å†™Providerä¿¡æ¯
   - ä¿å­˜

2. **é…ç½®API Key**
   - é€‰æ‹©Provider
   - ç‚¹å‡»"æ·»åŠ API Key"
   - å¡«å†™Keyä¿¡æ¯å’Œé€Ÿç‡é™åˆ¶
   - è®¾ç½®ä¼˜å…ˆçº§
   - ä¿å­˜

3. **åŒæ­¥æ¨¡å‹åˆ—è¡¨**
   - é€‰æ‹©Provider
   - ç‚¹å‡»"åŒæ­¥æ¨¡å‹"
   - ç³»ç»Ÿè‡ªåŠ¨ä»APIè·å–æœ€æ–°æ¨¡å‹

### 5.2 ç›‘æ§å’Œç»Ÿè®¡

1. **æŸ¥çœ‹ä½¿ç”¨è¶‹åŠ¿**
   - è¿›å…¥"ç»Ÿè®¡åˆ†æ"é¡µé¢
   - é€‰æ‹©æ—¶é—´èŒƒå›´
   - æŸ¥çœ‹è¯·æ±‚é‡ã€Tokenä½¿ç”¨é‡ã€æˆæœ¬è¶‹åŠ¿

2. **é”™è¯¯ç›‘æ§**
   - æŸ¥çœ‹é”™è¯¯ç‡
   - æŒ‰é”™è¯¯ç±»å‹åˆ†ç»„
   - æŒ‰Keyåˆ†ç»„æŸ¥çœ‹é—®é¢˜Key

3. **KeyçŠ¶æ€ç›‘æ§**
   - æŸ¥çœ‹æ¯ä¸ªKeyçš„ä½¿ç”¨æƒ…å†µ
   - ç›‘æ§é€Ÿç‡é™åˆ¶çŠ¶æ€
   - æŸ¥çœ‹æœ€åä½¿ç”¨æ—¶é—´

---

## 6. å¼€å‘é›†æˆ

### 6.1 åœ¨Serviceä¸­ä½¿ç”¨

```typescript
import { Injectable } from '@nestjs/common';
import { AIClientManagerService } from '../ai-models/services/ai-client-manager.service';

@Injectable()
export class LyricsService {
  constructor(
    private readonly aiClientManager: AIClientManagerService,
  ) {}

  async generateLyrics(theme: string, style: string, userId: number) {
    try {
      // ä½¿ç”¨DeepSeekç”Ÿæˆä¸­æ–‡æ­Œè¯(æ€§ä»·æ¯”é«˜)
      const response = await this.aiClientManager.createChatCompletion(
        'deepseek',
        {
          messages: [
            {
              role: 'system',
              content: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ­Œè¯åˆ›ä½œåŠ©æ‰‹ã€‚',
            },
            {
              role: 'user',
              content: `è¯·åˆ›ä½œä¸€é¦–å…³äº"${theme}"çš„${style}é£æ ¼æ­Œè¯ã€‚`,
            },
          ],
          model: 'deepseek-chat',
          maxTokens: 2000,
          temperature: 0.8,
        },
        userId,
      );

      return {
        lyrics: response.content,
        tokensUsed: response.usage.totalTokens,
        cost: this.calculateCost(response.usage),
      };
    } catch (error) {
      // é™çº§åˆ°OpenAI
      console.log('DeepSeek failed, falling back to OpenAI');
      
      const response = await this.aiClientManager.createChatCompletion(
        'openai',
        {
          messages: [...],
          model: 'gpt-3.5-turbo',
        },
        userId,
      );

      return {
        lyrics: response.content,
        tokensUsed: response.usage.totalTokens,
        cost: this.calculateCost(response.usage),
      };
    }
  }

  private calculateCost(usage: any): number {
    // æˆæœ¬å·²ç»åœ¨responseä¸­è®¡ç®—
    return usage.totalTokens * 0.001; // ç¤ºä¾‹
  }
}
```

### 6.2 æ‰¹é‡è°ƒç”¨

```typescript
async function batchGenerate() {
  const requests = [
    { messages: [{ role: 'user', content: 'Task 1' }] },
    { messages: [{ role: 'user', content: 'Task 2' }] },
    { messages: [{ role: 'user', content: 'Task 3' }] },
  ];

  const responses = await aiClientManager.batchCreateChatCompletion(
    'openai',
    requests,
    userId,
  );

  console.log(`Completed ${responses.length} tasks`);
}
```

### 6.3 Tokenè®¡æ•°

```typescript
// åœ¨å‘é€è¯·æ±‚å‰ä¼°ç®—tokenæ•°
const tokenCount = await aiClientManager.countTokens(
  'openai',
  longText,
  'gpt-4o',
);

console.log(`Estimated tokens: ${tokenCount}`);

// æ£€æŸ¥æ˜¯å¦ä¼šè¶…è¿‡é™åˆ¶
if (tokenCount > 100000) {
  console.log('Text too long, need to split');
}
```

---

## 7. æœ€ä½³å®è·µ

### 7.1 Provideré€‰æ‹©ç­–ç•¥

æ ¹æ®ä¸åŒåœºæ™¯é€‰æ‹©åˆé€‚çš„Providerï¼š

| åœºæ™¯ | æ¨èProvider | æ¨¡å‹ | åŸå›  |
|------|-------------|------|------|
| ä¸­æ–‡å†…å®¹ç”Ÿæˆ | DeepSeek | deepseek-chat | æ€§ä»·æ¯”é«˜ï¼Œä¸­æ–‡èƒ½åŠ›å¼º |
| è‹±æ–‡å†…å®¹ç”Ÿæˆ | OpenAI | gpt-4o-mini | å¹³è¡¡æ€§èƒ½å’Œæˆæœ¬ |
| å¤æ‚æ¨ç†ä»»åŠ¡ | Claude | claude-3-5-sonnet | æ¨ç†èƒ½åŠ›å¼º |
| ä»£ç ç”Ÿæˆ | DeepSeek | deepseek-coder | ä¸“é—¨ä¼˜åŒ– |
| å¤šæ¨¡æ€(å›¾ç‰‡) | OpenAI | gpt-4o | æ”¯æŒè§†è§‰ |
| é•¿ä¸Šä¸‹æ–‡ | Claude | claude-3-5-sonnet | 200Kä¸Šä¸‹æ–‡ |

### 7.2 æˆæœ¬ä¼˜åŒ–

```typescript
// 1. æ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©æ¨¡å‹
function selectModel(complexity: 'simple' | 'medium' | 'complex') {
  switch (complexity) {
    case 'simple':
      return { provider: 'deepseek', model: 'deepseek-chat' }; // æœ€ä¾¿å®œ
    case 'medium':
      return { provider: 'openai', model: 'gpt-4o-mini' };
    case 'complex':
      return { provider: 'openai', model: 'gpt-4o' };
  }
}

// 2. é™åˆ¶maxTokens
const response = await aiClientManager.createChatCompletion('openai', {
  messages: [...],
  maxTokens: 500, // é™åˆ¶è¾“å‡ºé•¿åº¦ï¼Œæ§åˆ¶æˆæœ¬
});

// 3. ä½¿ç”¨ç¼“å­˜(DeepSeekæ”¯æŒ)
// DeepSeekä¼šè‡ªåŠ¨ç¼“å­˜é‡å¤çš„promptï¼Œé™ä½æˆæœ¬
```

### 7.3 é”™è¯¯å¤„ç†

```typescript
async function robustAICall() {
  const providers = ['deepseek', 'openai', 'anthropic']; // é™çº§é“¾
  
  for (const provider of providers) {
    try {
      const response = await aiClientManager.createChatCompletion(
        provider,
        request,
        userId,
      );
      
      return response;
    } catch (error) {
      console.error(`${provider} failed: ${error.message}`);
      
      // å¦‚æœæ˜¯æœ€åä¸€ä¸ªproviderï¼ŒæŠ›å‡ºé”™è¯¯
      if (provider === providers[providers.length - 1]) {
        throw error;
      }
      
      // å¦åˆ™ç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªprovider
      continue;
    }
  }
}
```

### 7.4 é€Ÿç‡é™åˆ¶ç®¡ç†

```typescript
// ä¸ºä¸åŒçš„Keyè®¾ç½®ä¸åŒçš„é™åˆ¶
const keys = [
  {
    name: 'ä¸»Key',
    priority: 100,
    rateLimitRpm: 3500,  // OpenAI GPT-4oçš„RPMé™åˆ¶
    rateLimitTpm: 90000, // TPMé™åˆ¶
    rateLimitRpd: 200000, // æ¯æ—¥é™åˆ¶
  },
  {
    name: 'å¤‡ç”¨Key',
    priority: 90,
    rateLimitRpm: 3500,
    rateLimitTpm: 90000,
    rateLimitRpd: 200000,
  },
];

// ç³»ç»Ÿä¼šè‡ªåŠ¨è½®è¯¢ä½¿ç”¨ï¼Œé¿å…å•ä¸ªKeyè¾¾åˆ°é™åˆ¶
```

---

## 8. æ•…éšœæ’æŸ¥

### 8.1 å¸¸è§é”™è¯¯

#### é”™è¯¯1: "No available API keys"

**åŸå› **: æ‰€æœ‰Keyéƒ½ä¸å¯ç”¨æˆ–å·²è¾¾é€Ÿç‡é™åˆ¶

**è§£å†³æ–¹æ¡ˆ**:
1. æ£€æŸ¥KeyçŠ¶æ€: `GET /api/admin/ai-providers/1/keys`
2. æŸ¥çœ‹æ˜¯å¦æ‰€æœ‰Keyéƒ½è¾¾åˆ°äº†æ¯æ—¥é™åˆ¶
3. æ·»åŠ æ–°çš„Keyæˆ–ç­‰å¾…é™åˆ¶é‡ç½®

#### é”™è¯¯2: "Invalid API key"

**åŸå› **: API Keyæ— æ•ˆæˆ–å·²è¿‡æœŸ

**è§£å†³æ–¹æ¡ˆ**:
1. éªŒè¯Key: `POST /api/admin/ai-providers/keys/:id/validate`
2. æ£€æŸ¥Providerçš„API Keyæ˜¯å¦æ­£ç¡®
3. é‡æ–°ç”ŸæˆKeyå¹¶æ›´æ–°

#### é”™è¯¯3: é«˜é”™è¯¯ç‡

**åŸå› **: ç½‘ç»œé—®é¢˜ã€æœåŠ¡å™¨é—®é¢˜æˆ–é…ç½®é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:
1. æŸ¥çœ‹é”™è¯¯ç»Ÿè®¡: `GET /api/admin/ai-stats/logs/errors`
2. æ£€æŸ¥é”™è¯¯ç±»å‹åˆ†å¸ƒ
3. é’ˆå¯¹æ€§è§£å†³:
   - ç½‘ç»œé—®é¢˜: æ£€æŸ¥DNSã€é˜²ç«å¢™
   - æœåŠ¡å™¨é—®é¢˜: ç­‰å¾…Provideræ¢å¤
   - é…ç½®é”™è¯¯: æ£€æŸ¥baseUrlã€apiKeyç­‰

### 8.2 æ€§èƒ½ä¼˜åŒ–

#### é—®é¢˜: APIå“åº”æ…¢

**è¯Šæ–­**:
```sql
-- æŸ¥çœ‹å¹³å‡å»¶è¿Ÿ
SELECT 
  provider_id,
  AVG(latency_ms) as avg_latency,
  MAX(latency_ms) as max_latency
FROM t_ai_api_logs
WHERE created_at >= DATE_SUB(NOW(), INTERVAL 1 DAY)
GROUP BY provider_id;
```

**ä¼˜åŒ–**:
1. æ£€æŸ¥ç½‘ç»œå»¶è¿Ÿ
2. ä½¿ç”¨åœ°ç†ä½ç½®æ›´è¿‘çš„Provider
3. å¯ç”¨HTTP/2è¿æ¥
4. å¢åŠ è¶…æ—¶æ—¶é—´

#### é—®é¢˜: æ•°æ®åº“æ…¢

**è¯Šæ–­**:
```sql
-- æ£€æŸ¥æ…¢æŸ¥è¯¢
SHOW PROCESSLIST;

-- æ£€æŸ¥ç´¢å¼•ä½¿ç”¨
EXPLAIN SELECT * FROM t_ai_api_logs WHERE ...;
```

**ä¼˜åŒ–**:
1. æ·»åŠ ç´¢å¼•
2. å®šæœŸæ¸…ç†æ—§æ—¥å¿—
3. ä½¿ç”¨åˆ†åŒºè¡¨
4. è¯»å†™åˆ†ç¦»

### 8.3 æ—¥å¿—åˆ†æ

```typescript
// æŸ¥è¯¢æœ€è¿‘çš„é”™è¯¯æ—¥å¿—
const errors = await logService.queryLogs({
  status: 'error',
  startDate: new Date(Date.now() - 24 * 60 * 60 * 1000),
  page: 1,
  pageSize: 50,
});

// åˆ†æé”™è¯¯æ¨¡å¼
errors.logs.forEach(log => {
  console.log(`Error: ${log.errorCode}`);
  console.log(`Key: ${log.keyId}`);
  console.log(`Message: ${log.errorMessage}`);
});
```

---

## é™„å½•

### A. ç¯å¢ƒå˜é‡é…ç½®

```bash
# .env
DB_HOST=localhost
DB_PORT=3306
DB_USERNAME=root
DB_PASSWORD=your_password
DB_DATABASE=music_platform

# API Keys (ç”¨äºåˆå§‹åŒ–ï¼Œç”Ÿäº§ç¯å¢ƒåº”é€šè¿‡ç®¡ç†åå°æ·»åŠ )
# OPENAI_API_KEY=sk-proj-...
# ANTHROPIC_API_KEY=sk-ant-...
# DEEPSEEK_API_KEY=sk-...
```

### B. æ•°æ®åº“è¡¨ç»“æ„

è¯¦è§: `backend/src/database/migrations/07-create-ai-models-system.sql`

### C. APIé™åˆ¶å‚è€ƒ

| Provider | RPM | TPM | RPD |
|----------|-----|-----|-----|
| OpenAI GPT-4o | 3,500 | 90,000 | - |
| OpenAI GPT-4o-mini | 3,500 | 90,000 | - |
| Claude 3.5 Sonnet | 4,000 | 80,000 | - |
| DeepSeek | æ— é™åˆ¶ | æ— é™åˆ¶ | - |

*æ³¨: é™åˆ¶å¯èƒ½éšProvideræ”¿ç­–å˜åŒ–ï¼Œè¯·æŸ¥é˜…å®˜æ–¹æ–‡æ¡£*

---

**æ–‡æ¡£ç»´æŠ¤**: è¯·åœ¨ä¿®æ”¹ç³»ç»Ÿæ—¶åŒæ­¥æ›´æ–°æœ¬æ–‡æ¡£  
**æœ€åæ›´æ–°**: 2025-01-15
